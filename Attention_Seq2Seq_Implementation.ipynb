{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvNSZXNkkOkO"
   },
   "source": [
    "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
    "\n",
    "2. You will find **ita.txt** file in that ZIP, \n",
    "you can read that data and preprocess that data this way only: \n",
    "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
    "    \n",
    "\n",
    "3. Use BLEU score as metric to evaluate your model. You can use any loss function you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k_AlAuKJqVA"
   },
   "source": [
    "<font color='blue'>**Load the data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "fU80Ao-AGaob",
    "outputId": "3e7a86ff-9854-4780-8cc2-64a6c239d80a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-21 08:07:31--  http://www.manythings.org/anki/ita-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 172.67.173.198, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7468237 (7.1M) [application/zip]\n",
      "Saving to: ‘ita-eng.zip’\n",
      "\n",
      "ita-eng.zip         100%[===================>]   7.12M  4.54MB/s    in 1.6s    \n",
      "\n",
      "2020-09-21 08:07:32 (4.54 MB/s) - ‘ita-eng.zip’ saved [7468237/7468237]\n",
      "\n",
      "Archive:  ita-eng.zip\n",
      "  inflating: ita.txt                 \n",
      "  inflating: _about.txt              \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'ita.txt' not in os.listdir():\n",
    "    !wget http://www.manythings.org/anki/ita-eng.zip\n",
    "    !unzip ita-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "aWywfQGyiS1c",
    "outputId": "ce686af5-c4ee-44c1-989c-c65269d0d090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-21 08:07:33--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
      "--2020-09-21 08:07:33--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucebcc15bdee938723f0111297ad.dl.dropboxusercontent.com/cd/0/inline/A_w1Jfq6fuy_M0Bq1JhSrxtjtv8ojsPfiuRFyxIupXZ7OUkilF42HuNQJbAVMgYqiooj8O-oQ8F-Xyl0VAByAL4bEVH5rvK-jNOFJj1rEcAORHVJcrpOJRLJzBU5dvbEE24/file# [following]\n",
      "--2020-09-21 08:07:33--  https://ucebcc15bdee938723f0111297ad.dl.dropboxusercontent.com/cd/0/inline/A_w1Jfq6fuy_M0Bq1JhSrxtjtv8ojsPfiuRFyxIupXZ7OUkilF42HuNQJbAVMgYqiooj8O-oQ8F-Xyl0VAByAL4bEVH5rvK-jNOFJj1rEcAORHVJcrpOJRLJzBU5dvbEE24/file\n",
      "Resolving ucebcc15bdee938723f0111297ad.dl.dropboxusercontent.com (ucebcc15bdee938723f0111297ad.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
      "Connecting to ucebcc15bdee938723f0111297ad.dl.dropboxusercontent.com (ucebcc15bdee938723f0111297ad.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 347116733 (331M) [text/plain]\n",
      "Saving to: ‘glove.6B.100d.txt’\n",
      "\n",
      "glove.6B.100d.txt   100%[===================>] 331.04M  77.2MB/s    in 4.6s    \n",
      "\n",
      "2020-09-21 08:07:38 (72.7 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'glove.6B.100d.txt' not in os.listdir():\n",
    "    !wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v74GbUPliVuw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "tf.config.run_functions_eagerly(True)\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "gL4VAnR1UsdF",
    "outputId": "84186cc8-0dc8-413b-c824-fa0c06fd6d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15354251413126074276\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16090073807451913920\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1766355180172356503\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14640891840\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4373390264796627401\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "knpoB_N4iYSZ",
    "outputId": "7ac14db7-83e5-4d0f-ed0c-5e0dc90f2dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341554, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Chi?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   italian\n",
       "0     Hi.     Ciao!\n",
       "1    Run!    Corri!\n",
       "2    Run!    Corra!\n",
       "3    Run!  Correte!\n",
       "4    Who?      Chi?"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
    "    eng=[]\n",
    "    ita=[]\n",
    "    for i in f.readlines():\n",
    "        eng.append(i.split(\"\\t\")[0])\n",
    "        ita.append(i.split(\"\\t\")[1])\n",
    "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmGWTdRmKRph"
   },
   "source": [
    "<font color='blue'>**Preprocess data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "9QqElB_nKZos",
    "outputId": "c6f7a91f-238a-4787-a757-1fc37d152557"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi .</td>\n",
       "      <td>ciao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run !</td>\n",
       "      <td>corri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run !</td>\n",
       "      <td>corra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run !</td>\n",
       "      <td>correte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who ?</td>\n",
       "      <td>chi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   italian\n",
       "0   hi .      ciao \n",
       "1  run !     corri \n",
       "2  run !     corra \n",
       "3  run !   correte \n",
       "4  who ?       chi "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decontractions(phrase):\n",
    "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    # convert all the text into lower letters\n",
    "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
    "    # remove all the spacial characters: except space ' '\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", text) # puts a space between punctuations and words\n",
    "    #text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_ita(text):\n",
    "    # convert all the text into lower letters\n",
    "    # remove the words betweent brakets ()\n",
    "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
    "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
    "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
    "    # you are free to do more proprocessing\n",
    "    # note that the model will learn better with better preprocessed data \n",
    "    \n",
    "    text = text.lower()\n",
    "    #text = decontractions(text)\n",
    "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
    "    text = re.sub('\\u200b', ' ', text)\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    text = re.sub('-', ' ', text)\n",
    "    text = re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", text) # puts a space between punctuations and words\n",
    "    return text\n",
    "\n",
    "\n",
    "data['english'] = data['english'].apply(preprocess)\n",
    "data['italian'] = data['italian'].apply(preprocess_ita)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xZUxx1tiorv"
   },
   "outputs": [],
   "source": [
    "ita_lengths = data['italian'].str.split().apply(len)\n",
    "eng_lengths = data['english'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "6dJWnW1zipHi",
    "outputId": "ad2c03f7-04c9-4f9f-caeb-1d07db06569a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "10 3.0\n",
      "20 4.0\n",
      "30 4.0\n",
      "40 5.0\n",
      "50 5.0\n",
      "60 6.0\n",
      "70 6.0\n",
      "80 7.0\n",
      "90 8.0\n",
      "100 92.0\n",
      "---------------\n",
      "90 8.0\n",
      "91 8.0\n",
      "92 8.0\n",
      "93 9.0\n",
      "94 9.0\n",
      "95 9.0\n",
      "96 9.0\n",
      "97 10.0\n",
      "98 11.0\n",
      "99 12.0\n",
      "100 92.0\n",
      "---------------\n",
      "99.1 12.0\n",
      "99.2 12.0\n",
      "99.3 12.0\n",
      "99.4 13.0\n",
      "99.5 13.0\n",
      "99.6 14.0\n",
      "99.7 15.0\n",
      "99.8 16.0\n",
      "99.9 20.0\n",
      "100 92.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,10):\n",
    "    print(i,np.percentile(ita_lengths, i))\n",
    "print('-'*15)\n",
    "for i in range(90,101):\n",
    "    print(i,np.percentile(ita_lengths, i))\n",
    "print('-'*15)\n",
    "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
    "    print(i,np.percentile(ita_lengths, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "FgvQVbXAiqAK",
    "outputId": "6dce939d-c3e3-459a-cbfd-98efbf4aa544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.0\n",
      "10 5.0\n",
      "20 5.0\n",
      "30 6.0\n",
      "40 6.0\n",
      "50 7.0\n",
      "60 7.0\n",
      "70 8.0\n",
      "80 8.0\n",
      "90 10.0\n",
      "100 111.0\n",
      "---------------\n",
      "90 10.0\n",
      "91 10.0\n",
      "92 10.0\n",
      "93 10.0\n",
      "94 10.0\n",
      "95 11.0\n",
      "96 11.0\n",
      "97 11.0\n",
      "98 12.0\n",
      "99 13.0\n",
      "100 111.0\n",
      "---------------\n",
      "99.1 14.0\n",
      "99.2 14.0\n",
      "99.3 14.0\n",
      "99.4 15.0\n",
      "99.5 15.0\n",
      "99.6 16.0\n",
      "99.7 17.0\n",
      "99.8 18.0\n",
      "99.9 22.0\n",
      "100 111.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,10):\n",
    "    print(i,np.percentile(eng_lengths, i))\n",
    "print('-'*15)\n",
    "for i in range(90,101):\n",
    "    print(i,np.percentile(eng_lengths, i))\n",
    "print('-'*15)\n",
    "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
    "    print(i,np.percentile(eng_lengths, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "_i2xECEuirKS",
    "outputId": "9c9d1516-8ef7-4fc7-b885-658397ddb6bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi .</td>\n",
       "      <td>hi .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corri</td>\n",
       "      <td>&lt;start&gt; run !</td>\n",
       "      <td>run !  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corra</td>\n",
       "      <td>&lt;start&gt; run !</td>\n",
       "      <td>run !  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correte</td>\n",
       "      <td>&lt;start&gt; run !</td>\n",
       "      <td>run !  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chi</td>\n",
       "      <td>&lt;start&gt; who ?</td>\n",
       "      <td>who ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    italian     english_inp   english_out\n",
       "0     ciao    <start> hi .    hi .  <end>\n",
       "1    corri   <start> run !   run !  <end>\n",
       "2    corra   <start> run !   run !  <end>\n",
       "3  correte   <start> run !   run !  <end>\n",
       "4      chi   <start> who ?   who ?  <end>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['italian_len'] = data['italian'].str.split().apply(len)\n",
    "data = data[data['italian_len'] < 20]\n",
    "\n",
    "data['english_len'] = data['english'].str.split().apply(len)\n",
    "data = data[data['english_len'] < 20]\n",
    "\n",
    "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
    "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
    "\n",
    "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
    "# only for the first sentence add a token <end> so that we will have <end> in tokenizer\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQC0z1bmjxLW"
   },
   "source": [
    "### **Train-Test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "25Ouhz9NizVu",
    "outputId": "37a44b32-5c9c-4cef-f273-60c68ada0e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272866, 3) (68217, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data, test_size=0.2)\n",
    "print(train.shape, validation.shape)\n",
    "\n",
    "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
    "# with this we can use only one tokenizer for both encoder output and decoder output\n",
    "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
    "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "yxwPX0oZi9a2",
    "outputId": "eaf0ab8d-b8a9-4cd3-ba48-584be902451b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280488</th>\n",
       "      <td>la mappa mi aiutò a orientarmi</td>\n",
       "      <td>&lt;start&gt; the map helped me to orient myself .  ...</td>\n",
       "      <td>the map helped me to orient myself .  &lt;end&gt; &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140206</th>\n",
       "      <td>che stai facendo tom</td>\n",
       "      <td>&lt;start&gt; what are you doing , tom ?</td>\n",
       "      <td>what are you doing , tom ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55397</th>\n",
       "      <td>siete liberi di andare</td>\n",
       "      <td>&lt;start&gt; you are free to go .</td>\n",
       "      <td>you are free to go .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270174</th>\n",
       "      <td>voglio imparare a suonare il flauto</td>\n",
       "      <td>&lt;start&gt; i want to learn to play the flute .</td>\n",
       "      <td>i want to learn to play the flute .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210767</th>\n",
       "      <td>è tutto quello che vuoi sapere</td>\n",
       "      <td>&lt;start&gt; is that all you want to know ?</td>\n",
       "      <td>is that all you want to know ?  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     italian  ...                                        english_out\n",
       "280488       la mappa mi aiutò a orientarmi   ...  the map helped me to orient myself .  <end> <end>\n",
       "140206                 che stai facendo tom   ...                  what are you doing , tom ?  <end>\n",
       "55397                siete liberi di andare   ...                        you are free to go .  <end>\n",
       "270174  voglio imparare a suonare il flauto   ...         i want to learn to play the flute .  <end>\n",
       "210767       è tutto quello che vuoi sapere   ...              is that all you want to know ?  <end>\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ba59ll7bi-5m",
    "outputId": "4a52549a-7ae0-4c5f-c898-99193f657575"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10538</th>\n",
       "      <td>siamo adulti</td>\n",
       "      <td>&lt;start&gt; we are adults .</td>\n",
       "      <td>we are adults .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309181</th>\n",
       "      <td>io penso che il vostro inglese sia migliorato ...</td>\n",
       "      <td>&lt;start&gt; i think your english has improved a lo...</td>\n",
       "      <td>i think your english has improved a lot .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244856</th>\n",
       "      <td>tutti gli uomini sono uguali secondo la legge</td>\n",
       "      <td>&lt;start&gt; all men are equal under the law .</td>\n",
       "      <td>all men are equal under the law .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10754</th>\n",
       "      <td>mi auguri buona fortuna</td>\n",
       "      <td>&lt;start&gt; wish me luck .</td>\n",
       "      <td>wish me luck .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>io dormii fino allalba</td>\n",
       "      <td>&lt;start&gt; i slept till dawn .</td>\n",
       "      <td>i slept till dawn .  &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  italian  ...                                       english_out\n",
       "10538                                       siamo adulti   ...                            we are adults .  <end>\n",
       "309181  io penso che il vostro inglese sia migliorato ...  ...  i think your english has improved a lot .  <end>\n",
       "244856     tutti gli uomini sono uguali secondo la legge   ...          all men are equal under the law .  <end>\n",
       "10754                            mi auguri buona fortuna   ...                             wish me luck .  <end>\n",
       "47555                             io dormii fino allalba   ...                        i slept till dawn .  <end>\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "925r-E4VjLy3"
   },
   "source": [
    "### **Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "he5UYd1zjNIN"
   },
   "outputs": [],
   "source": [
    "tknizer_ita = Tokenizer()\n",
    "tknizer_ita.fit_on_texts(train['italian'].values)\n",
    "#tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')  # Notice this does not have '<' and '>' characters in the filter\n",
    "tknizer_eng = Tokenizer(filters='!\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')  # Notice this does not have '<' and '>' characters in the filter. Also removed punctuations like comma, full stop and question mark from filter\n",
    "tknizer_eng.fit_on_texts(train['english_inp'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmyV16YLKZw-"
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# tknizer_abc = Tokenizer(filters='!\"#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n')\n",
    "# abc_input = ['chintan , # dave . ', u\"machine learning's the future? \"]\n",
    "# for a in range(len(abc_input)):\n",
    "#     abc_input[a] = re.sub(r\"([\\w/'+$\\s-]+|[^\\w/'+$\\s-]+)\\s*\", r\"\\1 \", abc_input[a])\n",
    "# print(abc_input)\n",
    "# tknizer_abc.fit_on_texts(abc_input)\n",
    "# tknizer_abc.word_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "0hxgKWo_jUc7",
    "outputId": "82068757-4005-4e3f-9a92-1eb54003f5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12602\n",
      "26134\n"
     ]
    }
   ],
   "source": [
    "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
    "print(vocab_size_eng)\n",
    "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
    "print(vocab_size_ita)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPCjgxJ_jcGl"
   },
   "source": [
    "### **Embeddings for English sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gtl-R8DNjf_t"
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
    "for word, i in tknizer_eng.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jgBV9QOpjopW",
    "outputId": "e838f15f-5b2d-49e5-d799-109cfe7cfe25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12603, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "K98w92LSHjLd",
    "outputId": "ce81031f-f800-49ee-f883-56e230104be7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10004)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZhX3K9GLOfJ"
   },
   "source": [
    "# Machine Translation Using Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3d7GeBMGbsJ"
   },
   "source": [
    "* To implement an Encoder and Decoder architecture with attention\n",
    "* In Global attention, there are 3 types of scoring functions.\n",
    " I have created 3 models for each scoring function**\n",
    "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
    "\n",
    "    * In model 1 implemnted \"dot\" score function\n",
    "    * In model 2 implemnted \"general\" score function\n",
    "    * In model 3 implemnted \"concat\" score function.<br>\n",
    "\n",
    "* Resources:\n",
    "    a. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
    "    b. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
    "    c. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4KIsGxLOfK"
   },
   "source": [
    "## <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMm3ADQDLOfK"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lx_5NA24KzRp"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):\n",
    "        super().__init__()\n",
    "        self.enc_units= lstm_size\n",
    "        self.lstm_output=0\n",
    "        self.lstm_state_h=0\n",
    "        self.lstm_state_c=0\n",
    "\n",
    "        self.embedding = Embedding(input_dim=inp_vocab_size, output_dim=embedding_size, input_length=input_length,\n",
    "                           mask_zero=True )\n",
    "        self.lstm = LSTM(lstm_size, return_state=True, return_sequences=True )\n",
    "\n",
    "\n",
    "    def call(self, input_sequence, states):\n",
    "        '''\n",
    "        This function takes a sequence input and the initial states of the encoder.\n",
    "        Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "        returns -- All encoder_outputs, last time steps hidden and cell state\n",
    "        '''\n",
    "        input_embedd = self.embedding(input_sequence)\n",
    "        self.lstm_output, self.lstm_state_h, self.lstm_state_c = self.lstm(input_embedd, initial_state=states)\n",
    "        return self.lstm_output, self.lstm_state_h, self.lstm_state_c\n",
    "    \n",
    "    def initialize_states(self, batch_size):\n",
    "        '''\n",
    "        Given a batch size it will return intial hidden state and intial cell state.\n",
    "        If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "        '''\n",
    "        int_state_h = tf.zeros((batch_size, self.enc_units) )\n",
    "        int_state_c = tf.zeros((batch_size, self.enc_units) )\n",
    "        return int_state_h, int_state_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXn278lhLYRM"
   },
   "source": [
    "<font color='blue'>**Attention**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-9wIQISa13p"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    '''\n",
    "        Class that calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
    "    '''\n",
    "    def __init__(self, scoring_function, att_units):\n",
    "        super().__init__()\n",
    "        self.lstm_size_e = att_units\n",
    "        self.lstm_size_d = att_units\n",
    "        self.scoring_function = scoring_function\n",
    " \n",
    "        # Please go through the reference notebook and research paper to complete the scoring functions\n",
    "        if self.scoring_function=='dot':\n",
    "            # Intialize variables needed for Dot score function here\n",
    "            pass\n",
    "        if self.scoring_function == 'general':\n",
    "            # Intialize variables needed for General score function here\n",
    "            pass\n",
    "        elif self.scoring_function == 'concat':\n",
    "            # Intialize variables needed for Concat score function here\n",
    "            pass\n",
    " \n",
    " \n",
    "    def build(self, input_shape):\n",
    "        if self.scoring_function == 'general':\n",
    "            self.w_general = self.add_weight(shape=(self.lstm_size_e, self.lstm_size_d), initializer='random_normal', trainable=True, name='w_gen')\n",
    "        elif self.scoring_function == 'concat':\n",
    "            k=128\n",
    "            self.w_concat_e = self.add_weight(shape=(self.lstm_size_e, k), initializer='random_normal', trainable=True, name='w_concat_1') # To be multiplied with encoder\n",
    "            self.w_concat_d = self.add_weight(shape=(self.lstm_size_d, k), initializer='random_normal', trainable=True, name='w_concat_2') # To be multiplied with decoder\n",
    "            self.w_v = self.add_weight(shape=(k, 1), initializer='random_normal', trainable=True, name='w_concat_v') # To be finally multiplied with tanh\n",
    " \n",
    " \n",
    "    def call(self, decoder_hidden_state, encoder_output):\n",
    "        '''\n",
    "            Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "            * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "            Multiply the score function with your encoder_outputs to get the context vector.\n",
    "            Function returns context vector and attention weights(softmax - scores)\n",
    "        '''\n",
    " \n",
    "        if self.scoring_function == 'dot':\n",
    "            # Implement Dot score function here\n",
    "            # encoder_output = [batch_size, input_length, att_units]\n",
    "            # decoder_hidden_state = [batch_size, att_units]\n",
    " \n",
    "            decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=2) # [batch_size, att_units, 1]\n",
    " \n",
    "            sim = tf.matmul(encoder_output, decoder_hidden_state) # Similarity values\n",
    "            # Now we have to pass this sim values to a softmax layer. As a result we will get the alpha values.\n",
    "            \n",
    "            sim = tf.squeeze(sim, axis=2)   # [batch_size,input_length]\n",
    "            alphas = Dense(encoder_output.shape[1], activation='softmax')(sim) # encoder_output.shape[1] is input_seq_length i.e. the num of enc hidden states\n",
    "            alphas = tf.expand_dims(alphas, axis=2)\n",
    "            # Now we have to multiply these alphas values to the all the encoder timesteps to get the context vectors\n",
    " \n",
    "            encoder_output = tf.transpose(encoder_output, perm=[0,2,1])\n",
    "            context_vectors = tf.matmul(encoder_output, alphas) # [batch_size, att_units, 1]\n",
    "            context_vectors = tf.squeeze(context_vectors, axis=2)   # [batch_size, att_units]\n",
    "            return context_vectors, alphas\n",
    "            \"\"\"encoder_output shape= (16, 10, 32)\n",
    "            decoder_hidden shape= (16, 32, 1)\n",
    "            sim shape= (16, 10)\n",
    "            alphas shape= (16, 10, 1)\n",
    "            context vecotr shape= (16, 32)\"\"\"\n",
    "        elif self.scoring_function == 'general':\n",
    "            # Implement General score function here\n",
    "            # encoder_output = [batch_size, input_length, att_units]\n",
    "            # decoder_hidden_state = [batch_size, att_units]\n",
    "            \n",
    "            decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=2)\n",
    "            \n",
    "            # self.w_general = [enc_att_units, dec_att_units]\n",
    "            sim = tf.matmul(tf.matmul(encoder_output, self.w_general), decoder_hidden_state)\n",
    "            sim = tf.squeeze(sim, axis=2)\n",
    " \n",
    "            alphas = Dense(encoder_output.shape[1], activation='softmax')(sim)\n",
    "            alphas = tf.expand_dims(alphas, axis=2)\n",
    "            # Now we have to multiply these alphas values to the all the encoder timesteps to get the context vectors\n",
    " \n",
    "            encoder_output = tf.transpose(encoder_output, perm=[0,2,1])\n",
    "            context_vectors = tf.matmul(encoder_output, alphas)\n",
    "            context_vectors = tf.squeeze(context_vectors, axis=2)\n",
    "            return context_vectors, alphas\n",
    "        elif self.scoring_function == 'concat':\n",
    "            # Implement General score function here\n",
    "            # encoder_output = [batch_size, input_length, att_units]\n",
    "            # decoder_hidden_state = [batch_size, att_units]\n",
    "            \n",
    "            decoder_hidden_state = tf.expand_dims(decoder_hidden_state, axis=1)\n",
    "            \n",
    "            # self.w_concat_e = [enc_att_units, k]\n",
    "            # self.w_concat_d = [dec_att_units, k]\n",
    "            # self.w_v = [k,1]\n",
    "            mat_mul_1 = tf.matmul(encoder_output, self.w_concat_e)\n",
    "            mat_mul_2 = tf.matmul(decoder_hidden_state, self.w_concat_d)\n",
    "            mat_mul_added = mat_mul_1 + mat_mul_2\n",
    "            tanh_ = tf.math.tanh(mat_mul_added)\n",
    "            sim = tf.matmul(tanh_, self.w_v)\n",
    "            sim = tf.squeeze(sim, axis=2)\n",
    " \n",
    "            alphas = Dense(encoder_output.shape[1], activation='softmax')(sim)\n",
    "            alphas = tf.expand_dims(alphas, axis=2)\n",
    "            # Now we have to multiply these alphas values to the all the encoder timesteps to get the context vectors\n",
    "            \n",
    "            encoder_output = tf.transpose(encoder_output, perm=[0,2,1])\n",
    "            context_vectors = tf.matmul(encoder_output, alphas)\n",
    "            context_vectors = tf.squeeze(context_vectors, axis=2)\n",
    "            return context_vectors, alphas\n",
    "            \"\"\"encoder_output shape= (16, 10, 32)\n",
    "            decoder_hidden shape= (16, 1, 32)\n",
    "            mat mul added shape= (16, 10, 32)\n",
    "            tanh_ shape= (16, 10, 32)\n",
    "            sim shape= (16, 10)\n",
    "            alphas shape= (16, 10, 1)\n",
    "            context vecotr shape= (16, 32)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic-FNEbfL2DN"
   },
   "source": [
    "<font color='blue'>**OneStepDecoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kc8m7lmOL097"
   },
   "outputs": [],
   "source": [
    "class One_Step_Decoder(tf.keras.Model):\n",
    "    def __init__(self, out_vocab_size, embedding_size, input_length, dec_units ,score_fun ,att_units):\n",
    "        super().__init__()\n",
    "        \"\"\"self.att_units = att_units\n",
    "        self.score_fun = score_fun\n",
    "        self.vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_size\n",
    "        self.dec_units = dec_units\n",
    "        self.input_length = input_length\"\"\"\n",
    "        \n",
    "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "        #, weights=[embedding_matrix]\n",
    "        self.embedding = Embedding(input_dim=out_vocab_size, output_dim=embedding_size, input_length=input_length, mask_zero=True, weights=[embedding_matrix], trainable=False)\n",
    "        self.lstm = LSTM(dec_units, return_sequences=True, return_state=True )\n",
    "        self.attention = Attention(score_fun, att_units)\n",
    "        #self.dense_softmax = Dense(out_vocab_size, activation='softmax' )  # DO NOT DO SOFTMAX HERE!!\n",
    "        self.dense = Dense(out_vocab_size)\n",
    "     \n",
    "    \n",
    "    def call(self, input_to_decoder, encoder_output, state_h, state_c):\n",
    "        '''\n",
    "            One step decoder mechanisim step by step:\n",
    "            A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
    "            B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "            C. Concat the context vector with the step A output\n",
    "            D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
    "            E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
    "            F. Return the states from step D, output from Step E, attention weights from Step -B\n",
    "        '''\n",
    "        context_vector, attention_weights = self.attention(state_h, encoder_output)\n",
    "        target_embedd = self.embedding(input_to_decoder)    # [batch_size, 1, embedding_dim]. Here the 1 is the timestep, because remember this is 'one step decoder'\n",
    "        \n",
    "        # Concatenate context vector and embedding output\n",
    "        context_vector_ = tf.expand_dims(context_vector, axis=1)    # [batch_size, 1, embedding_dim]\n",
    "        concate = tf.concat([target_embedd, context_vector_], axis=-1) \n",
    "        lstm_output, state_h_out, state_c_out  = self.lstm(concate, initial_state=[state_h, state_c])\n",
    "\n",
    "        # Pass the lstm_output to a softmax layer\n",
    "        lstm_output = tf.squeeze(lstm_output, axis=1)\n",
    "        dense_output = self.dense(lstm_output)\n",
    "        return dense_output, state_h_out, state_c_out, attention_weights, context_vector\n",
    "        \"\"\"context_vector shape= (32, 16)\n",
    "        input_to_decoder= (32, 1)\n",
    "        embedd shape= (32, 1, 12)\n",
    "        concate shape= (32, 1, 28)\n",
    "        lstm_output shape= (32, 1, 16)\n",
    "        lstm_output to Dense shape= (32, 16)\n",
    "        state_h_out shape= (32, 16)\n",
    "        state_c_out shape= (32, 16)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FHrurjUMGAi"
   },
   "source": [
    "<font color='blue'>**Decoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NV-x31rj6Hc4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, out_vocab_size, embedding_dim, input_length, dec_units, score_fun, att_units):\n",
    "        #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_length = input_length\n",
    "        \"\"\"self.vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\"\"\"\n",
    "\n",
    "        self.one_step_decoder = One_Step_Decoder(out_vocab_size, embedding_dim, input_length, dec_units, score_fun, att_units)\n",
    "\n",
    "\n",
    "    def call(self, input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state):\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        \n",
    "        #Iterate till the length of the decoder input\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            # Store the output in tensorarray\n",
    "        # Return the tensor array\n",
    "        \n",
    "        # input_to_decoder = [batch_size, input_seq_length]\n",
    "        all_outputs = tf.TensorArray(dtype='float32', size=self.input_length)\n",
    "        for timestep in range(self.input_length):\n",
    "            output, decoder_hidden_state, decoder_cell_state, attention_weights, context_vector = self.one_step_decoder(input_to_decoder[:, timestep:timestep+1], encoder_output, decoder_hidden_state, decoder_cell_state)\n",
    "            # append the output to the all_outputs and at the end return it.\n",
    "            all_outputs = all_outputs.write(timestep, output)\n",
    "        # each output is of shape [batch_size, out_vocab_size]\n",
    "        all_outputs = tf.transpose(all_outputs.stack(), perm=[1,0,2])\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC1T1EOoMTqC"
   },
   "source": [
    "<font color='blue'>**Encoder Decoder model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woOvuMq48G15"
   },
   "outputs": [],
   "source": [
    "GLOBAL_BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfqBIe20MT3D"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size_ita, vocab_size_eng, encoder_inputs_length, decoder_inputs_length, embedding_dim, score_fun, att_units):\n",
    "        super().__init__()\n",
    "        \"\"\"self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder_inputs_length = encoder_inputs_length\n",
    "        self.decoder_inputs_length = decoder_inputs_length\n",
    "\n",
    "        self.vocab_size_ita = vocab_size_ita\n",
    "        self.vocab_size_eng = vocab_size_eng\"\"\"\n",
    "\n",
    "        #Intialize objects from encoder decoder\n",
    "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita+1, embedding_size=embedding_dim, lstm_size=att_units, input_length=encoder_inputs_length)\n",
    "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1, embedding_dim=embedding_dim, input_length=decoder_inputs_length, dec_units=att_units, score_fun=score_fun, att_units=att_units)\n",
    "\n",
    "\n",
    "    def call(self, data):\n",
    "        # Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "        # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "        # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "        # return the decoder output\n",
    "        input_sequence, input_to_decoder = data[0], data[1]\n",
    "        # input_sequence = [batch_size, input_length]\n",
    "        initial_state=self.encoder.initialize_states(batch_size=GLOBAL_BATCH_SIZE)\n",
    "        encoder_output, enc_state_h, enc_state_c = self.encoder(input_sequence, initial_state)\n",
    "        all_outputs = self.decoder(input_to_decoder, encoder_output, enc_state_h, enc_state_c)\n",
    "        # all_outputs = [batch_size, input_length, out_vocab_size]\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRxB-FDMJWL"
   },
   "source": [
    "<font color='blue'>**Custom loss function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOTjI36LpoRA"
   },
   "outputs": [],
   "source": [
    "# Custom loss function that will not consider the loss for padded zeros\n",
    "# Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "# Below the pred is also called logits\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QlbWAqNNlqe"
   },
   "source": [
    "<font color='blue'>**Training**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2rXxrRos31-"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
    "        self.encoder_inps = data['italian'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tknizer_eng = tknizer_eng\n",
    "        self.tknizer_ita = tknizer_ita\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post', truncating='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post', truncating='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post', truncating='pre')\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "        \n",
    "    def __len__(self): # your model.fit_gen requires this function\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "\n",
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "        return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "    def __len__(self):  # your model.fit_gen requires this function\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "UZ63_lLfwEzg",
    "outputId": "347b5f45-5ed8-43d5-8a4d-d215909bd66d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 20) (1024, 20) (1024, 20)\n",
      "(1024, 20) (1024, 20) (1024, 20)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 20)\n",
    "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 20)\n",
    "\n",
    "train_dataloader = Dataloader(train_dataset, batch_size=GLOBAL_BATCH_SIZE)\n",
    "test_dataloader = Dataloader(test_dataset, batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)\n",
    "print(test_dataloader[0][0][0].shape, test_dataloader[0][0][1].shape, test_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqtZUQF2NuZE"
   },
   "source": [
    "Implement dot function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "02HERHmBPxrn",
    "outputId": "7e9ab75b-c11d-4ecf-fc27-2b2dad60664b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "\n",
    "log_dir=\"/content/drive/My Drive/Colab Notebooks/NLP Attention Mechanism/logs/dot/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKAKkUxORPtq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# https://stackoverflow.com/a/42963385/7697658\n",
    "lrschedule_cond_1 = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "T5w5ds2CHbYL",
    "outputId": "18253cbe-80a6-4b54-885d-1540a43d83a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272866, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "9yYMwmnitD7b",
    "outputId": "caba7750-09bb-43e0-c603-32e06e49d3c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/266 [..............................] - ETA: 0s - loss: 3.7225WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "266/266 [==============================] - 194s 731ms/step - loss: 1.4565 - val_loss: 0.9742\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 194s 728ms/step - loss: 0.7080 - val_loss: 0.4489\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 192s 720ms/step - loss: 0.3728 - val_loss: 0.2589\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 192s 723ms/step - loss: 0.2416 - val_loss: 0.1791\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 194s 730ms/step - loss: 0.1795 - val_loss: 0.1379\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 193s 725ms/step - loss: 0.1435 - val_loss: 0.1138\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 192s 723ms/step - loss: 0.1207 - val_loss: 0.0985\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 193s 725ms/step - loss: 0.1047 - val_loss: 0.0847\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 190s 714ms/step - loss: 0.0928 - val_loss: 0.0753\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 191s 716ms/step - loss: 0.0847 - val_loss: 0.0702\n",
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  2972968   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  5114488   \n",
      "=================================================================\n",
      "Total params: 8,087,456\n",
      "Trainable params: 6,830,656\n",
      "Non-trainable params: 1,256,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "\n",
    "model_attention = encoder_decoder(vocab_size_ita, vocab_size_eng, encoder_inputs_length=20, decoder_inputs_length=20, embedding_dim=100, score_fun='dot', att_units=256)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_attention.compile(optimizer=opt, loss=loss_function)\n",
    "train_steps=train.shape[0]//GLOBAL_BATCH_SIZE\n",
    "valid_steps=validation.shape[0]//GLOBAL_BATCH_SIZE\n",
    "model_attention.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=train_dataloader, validation_steps=valid_steps, callbacks=[lrschedule_cond_1, tensorboard_callback])\n",
    "model_attention.summary()\n",
    "\n",
    "#save_model_path = \"/content/drive/My Drive/Colab Notebooks/NLP Attention Mechanism/New Attention Mech/Model_Best_Dot/BEST_MODEL_ED.h5\"\n",
    "#model_attention.save_weights(save_model_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DpC9zlzMcXp"
   },
   "source": [
    "## <font color='blue'>**Inference**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1IhdBrgQYJr"
   },
   "source": [
    "<font color='blue'>**Predict the sentence translation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq64i9pxx11U"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence, model_ed, tknizer_ita, tknizer_eng):\n",
    "    '''\n",
    "        A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "        B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "        C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "        D. till we reach max_length of decoder or till the model predicted word <end>:\n",
    "                predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "                Save the attention weights\n",
    "                And get the word using the tokenizer(word index) and then store it in a string.\n",
    "        E. Call plot_attention(#params)\n",
    "        F. Return the predicted sentence\n",
    "    '''\n",
    "    ita_seq = tknizer_ita.texts_to_sequences([input_sentence])\n",
    "    initial_state = model_ed.layers[0].initialize_states(batch_size=1)\n",
    "    enc_output, state_h, state_c = model_ed.layers[0](np.array(ita_seq), initial_state)\n",
    "    attention_weights_lst = []  #attention weights for each timestep in one step decoder\n",
    "    pred_indexes = []\n",
    "    predicted_sentence=''\n",
    "    cur_vec = np.array(tknizer_eng.word_index['<start>']).reshape((1,1))\n",
    "    cur_vec = tf.convert_to_tensor(cur_vec)\n",
    "    for i in range(20):\n",
    "        output, state_h, state_c, attention_weights, context_vector = model_ed.layers[1].one_step_decoder(cur_vec, enc_output, state_h, state_c)\n",
    "        attention_weights_lst.append(attention_weights)\n",
    "        word_index = np.argmax(output)\n",
    "        cur_vec = np.reshape(word_index, (1,1))\n",
    "        for k, v in tknizer_eng.word_index.items():\n",
    "            if v == word_index:\n",
    "                predicted_sentence += k +' '\n",
    "                break\n",
    "\n",
    "        if k =='<end>':\n",
    "            pred_indexes.append(word_index)\n",
    "            return pred_indexes, predicted_sentence, np.array(attention_weights_lst).squeeze(axis=1).squeeze(axis=2)\n",
    "\n",
    "        pred_indexes.append(word_index)\n",
    "    return pred_indexes, predicted_sentence, np.array(attention_weights_lst).squeeze(axis=1).squeeze(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Wdj4lWlQx11a",
    "outputId": "d0d67684-abc3-4187-ad37-f5106ce8f774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i did not drink too much . <end> \n"
     ]
    }
   ],
   "source": [
    "input_sent = \"non ho bevuto troppo\"\n",
    "pred_tokens, predicted_sentence, all_attention_weights = predict(input_sent, model_attention, tknizer_ita, tknizer_eng)\n",
    "print(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Bkeyeuvz4qPU",
    "outputId": "5eb71745-69dd-40db-cfbe-bddd81b0b572"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_attention_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5NhESYyMW_t"
   },
   "source": [
    "<font color='blue'>**Plot attention weights**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyNQH7uPm4-8"
   },
   "outputs": [],
   "source": [
    "#Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "dOTjYasR6HFs",
    "outputId": "264e1486-85c2-499a-c167-35747cfefdc0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(all_attention_weights,  input_sent.split(' '), predicted_sentence.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmxIVOOQPWMu"
   },
   "source": [
    "<font color='blue'>**Calculate BLEU score**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdUWIGkdE1qu"
   },
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "def calculate_bleu(model, tknizer_ita, tknizer_eng):\n",
    "    bleu_scores = []\n",
    "    thousand_samples = data.sample(1000)\n",
    "    thousand_samples = thousand_samples[['italian','english_out']]\n",
    "    for input_sent, reference in thousand_samples.values:\n",
    "        pred_tokens, predicted_sentence, all_attention_weights = predict(input_sent, model, tknizer_ita, tknizer_eng)\n",
    "        reference = reference.split() # the original, from the dataframe\n",
    "        translation = predicted_sentence.split() # traslated using model\n",
    "        bleu_scores.append(bleu.sentence_bleu(reference, translation))\n",
    "    avg_bleu_score = np.mean(bleu_scores)\n",
    "    return avg_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "UeC6tZl-Lrlf",
    "outputId": "dd087513-eb52-4a90-dfc4-536c83b6b930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Bleu Score 'Dot'= 0.6302854734438311\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Bleu Score 'Dot'=\",calculate_bleu(model_attention, tknizer_ita, tknizer_eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWg2ferDQvT3"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "0Kpmn-j5EWra",
    "outputId": "659a5256-dacb-4fc4-993a-919a8e308b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "\n",
    "log_dir=\"/content/drive/My Drive/Colab Notebooks/NLP Attention Mechanism/logs/general/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "gsBUy8VIEWrf",
    "outputId": "68170cb1-484f-481b-cea9-43ded24d5ef3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/266 [..............................] - ETA: 0s - loss: 3.7379WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "266/266 [==============================] - 226s 851ms/step - loss: 1.5086 - val_loss: 1.0848\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 225s 845ms/step - loss: 0.8020 - val_loss: 0.5145\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 224s 843ms/step - loss: 0.4074 - val_loss: 0.2748\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 226s 850ms/step - loss: 0.2539 - val_loss: 0.1899\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 226s 848ms/step - loss: 0.1851 - val_loss: 0.1398\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 224s 842ms/step - loss: 0.1457 - val_loss: 0.1164\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 224s 843ms/step - loss: 0.1224 - val_loss: 0.1007\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 225s 844ms/step - loss: 0.1063 - val_loss: 0.0866\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 224s 841ms/step - loss: 0.0944 - val_loss: 0.0785\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 224s 842ms/step - loss: 0.0857 - val_loss: 0.0708\n",
      "Model: \"encoder_decoder_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_3 (Encoder)          multiple                  2974168   \n",
      "_________________________________________________________________\n",
      "decoder_3 (Decoder)          multiple                  5195018   \n",
      "=================================================================\n",
      "Total params: 8,169,186\n",
      "Trainable params: 6,908,186\n",
      "Non-trainable params: 1,261,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "\n",
    "model_attention_gen = encoder_decoder(vocab_size_ita, vocab_size_eng, encoder_inputs_length=20, decoder_inputs_length=20, embedding_dim=100, score_fun='general', att_units=256)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_attention_gen.compile(optimizer=opt, loss=loss_function)\n",
    "train_steps=train.shape[0]//GLOBAL_BATCH_SIZE\n",
    "valid_steps=validation.shape[0]//GLOBAL_BATCH_SIZE\n",
    "model_attention_gen.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=train_dataloader, validation_steps=valid_steps, callbacks=[tensorboard_callback])\n",
    "model_attention_gen.summary()\n",
    "\n",
    "#save_model_path = \"/content/drive/My Drive/Colab Notebooks/NLP Attention Mechanism/New Attention Mech/Model_Best_Dot/BEST_MODEL_ED\"\n",
    "#model_attention_gen.save_weights(save_model_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "8zn6T2jlErpA",
    "outputId": "c9ab93ca-3b80-4d18-8e5f-88d8a15dd19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i did not drink too much . <end> \n"
     ]
    }
   ],
   "source": [
    "input_sent = \"non ho bevuto troppo\"\n",
    "pred_tokens, predicted_sentence, all_attention_weights = predict(input_sent, model_attention_gen, tknizer_ita, tknizer_eng)\n",
    "print(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "wUim-tlRExDl",
    "outputId": "4065e2ab-ad7f-47b7-e9d1-a86ef6e2dc18"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(all_attention_weights,  input_sent.split(' '), predicted_sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0Ys7WtftCQp"
   },
   "outputs": [],
   "source": [
    "!zip -r logs.zip logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Bvkr4WKNExvb",
    "outputId": "97290f5c-53b7-44d2-a68f-850f670a0295"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Bleu Score 'General'= 0.6367642238033103\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Bleu Score 'General'=\",calculate_bleu(model_attention_gen, tknizer_ita, tknizer_eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB1jRUqZQ9AM"
   },
   "source": [
    "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zsAGKdjhGKlS",
    "outputId": "3396cd29-576b-42f2-924b-225193ac8bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "\n",
    "log_dir=\"/content/drive/My Drive/Colab Notebooks/NLP Attention Mechanism/logs/concat/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_grads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "VFA7zdWRGKld",
    "outputId": "1d92b455-a9c3-463e-f844-5fe54efde4fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/266 [..............................] - ETA: 0s - loss: 3.7388WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "266/266 [==============================] - 223s 840ms/step - loss: 1.5059 - val_loss: 1.0771\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 221s 831ms/step - loss: 0.8084 - val_loss: 0.5478\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 220s 826ms/step - loss: 0.4414 - val_loss: 0.3126\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 219s 824ms/step - loss: 0.2892 - val_loss: 0.2203\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 219s 821ms/step - loss: 0.2160 - val_loss: 0.1697\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 218s 820ms/step - loss: 0.1731 - val_loss: 0.1404\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 218s 820ms/step - loss: 0.1443 - val_loss: 0.1158\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 218s 821ms/step - loss: 0.1239 - val_loss: 0.1024\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 218s 820ms/step - loss: 0.1096 - val_loss: 0.0877\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 218s 820ms/step - loss: 0.0982 - val_loss: 0.0809\n",
      "Model: \"encoder_decoder_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Encoder)          multiple                  2976468   \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  5206213   \n",
      "=================================================================\n",
      "Total params: 8,182,681\n",
      "Trainable params: 6,918,581\n",
      "Non-trainable params: 1,264,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create an object of encoder_decoder Model class, \n",
    "# Compile the model and fit the model\n",
    "\n",
    "model_attention_concat = encoder_decoder(vocab_size_ita, vocab_size_eng, encoder_inputs_length=20, decoder_inputs_length=20, embedding_dim=100, score_fun='concat', att_units=256)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_attention_concat.compile(optimizer=opt, loss=loss_function)\n",
    "train_steps=train.shape[0]//GLOBAL_BATCH_SIZE\n",
    "valid_steps=validation.shape[0]//GLOBAL_BATCH_SIZE\n",
    "model_attention_concat.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=train_dataloader, validation_steps=valid_steps, callbacks=[tensorboard_callback])\n",
    "model_attention_concat.summary()\n",
    "\n",
    "#save_model_path = \"/content/drive/My Drive/Colab Notebooks/NLP Attention Mechanism/New Attention Mech/Model_Best_Concat/BEST_MODEL_ED\"\n",
    "#model_attention.save_weights(save_model_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wCr4ZIgFGKlj",
    "outputId": "d382bf25-9578-4b2e-803e-910acfb9023b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i did not too drunk . <end> \n"
     ]
    }
   ],
   "source": [
    "input_sent = \"non ho bevuto troppo\"\n",
    "pred_tokens, predicted_sentence, all_attention_weights = predict(input_sent, model_attention_concat, tknizer_ita, tknizer_eng)\n",
    "print(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "tRChSRtiGKlo",
    "outputId": "d05705c3-d988-4220-d735-bde88b4e3ce5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(all_attention_weights,  input_sent.split(' '), predicted_sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "0_yHHTstGKls",
    "outputId": "6b85ddc0-df4d-4c06-d571-f0061a965930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Bleu Score 'Concat'= 0.6070069372989185\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Bleu Score 'Concat'=\",calculate_bleu(model_attention_concat, tknizer_ita, tknizer_eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HM7gPwR5Gqsd"
   },
   "source": [
    "### **<font color='purple'>Comparision of 3 models on Attention Mechanism</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtWdD65TG1gm"
   },
   "source": [
    "<ul>\n",
    "<li>\n",
    "Here, Bahdanau's attention mechanism is implemented. Three scoring function of attentions are implemented here. The following are the observations on each of the scoring functions.\n",
    "    <ul>\n",
    "        <li><b>dot: </b> This function needs same number of lstm units in the encoder and the decoder. The <b>loss is 0.0702 & Bleu score is 0.6303</b></li>\n",
    "    </ul>\n",
    "    <ul>\n",
    "        <li><b>general: </b> This function can have different number of lstm units in the encoder and the decoder. We had to add a trainable weight matrix such that we can do a dot product on the encoder hidden states and the decoder hidden states. The <b>loss is 0.0708 & Bleu score is 0.6368</b></li>\n",
    "    </ul>\n",
    "    <ul>\n",
    "        <li><b>concat: </b> This function can also have different number of lstm units in the encoder and the decoder. We had to add three trainable weight matrices, where one will be multiplied with the encoder hidden states, secong will be multiplied with the decoder hidden states and the third one will be multiplied after applying tanh on the addition of first two multiplications. The <b>loss is 0.0809 & Bleu score is 0.6070</b></li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li>Let's see what the attention plots of each scoring functions say.</li>\n",
    "    <ul>\n",
    "        <li><b>dot: </b> We can see that the dot function is focusing <b><i>bevuto</i></b> which means to drink, with the english words <b>did</b> and <b>drink</b></li>\n",
    "    </ul>\n",
    "    <ul>\n",
    "        <li><b>general: </b> We can see that the general function is also giving us similar results, as it is focusing on <b><i>bevuto</i></b> which means to drink, with the english words <b>did</b> and <b>drink</b>. We can observe that this scoring function is sharply giving attention to fewer words and not spreading it across the predicted words.</li>\n",
    "    </ul>\n",
    "    <ul>\n",
    "        <li><b>concat: </b> We can see that the concat function is focusing on <b><i>troppo</i></b> which means too much, with the english word <b>too</b>. The word <b><i>ho</i></b> which means 'I', is also giving attention on the english word <b>'I'</b> in the predicted sentence. We can observe that this scoring function is spreading it's attention to many words at a time, along with focusing more on the important words. However, we saw that this scoring function didn't predict the english word 'much'. This may be due to the spread of attention, that it couldn't give much attention to that word.</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "<b>PS: </b> All the three models are trained on 10 epochs, so that a fair comparision can be made on the losses, bleu scores and the predicted sentences."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QyfZo8fmLOec"
   ],
   "name": "Attention_Seq2SeqImplementation__Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
